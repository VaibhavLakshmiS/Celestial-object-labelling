{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59d619e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1180/1250 [===========================>..] - ETA: 0s - loss: 0.4615 - accuracy: 0.7829\n",
      "Epoch 1: val_loss improved from inf to 0.18947, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 783us/step - loss: 0.4504 - accuracy: 0.7890 - val_loss: 0.1895 - val_accuracy: 0.9399 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1230/1250 [============================>.] - ETA: 0s - loss: 0.2247 - accuracy: 0.9131\n",
      "Epoch 2: val_loss improved from 0.18947 to 0.15358, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 985us/step - loss: 0.2246 - accuracy: 0.9133 - val_loss: 0.1536 - val_accuracy: 0.9515 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1200/1250 [===========================>..] - ETA: 0s - loss: 0.1838 - accuracy: 0.9321\n",
      "Epoch 3: val_loss improved from 0.15358 to 0.15173, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 760us/step - loss: 0.1830 - accuracy: 0.9323 - val_loss: 0.1517 - val_accuracy: 0.9534 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1210/1250 [============================>.] - ETA: 0s - loss: 0.1725 - accuracy: 0.9367\n",
      "Epoch 4: val_loss did not improve from 0.15173\n",
      "1250/1250 [==============================] - 1s 745us/step - loss: 0.1718 - accuracy: 0.9373 - val_loss: 0.1588 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1175/1250 [===========================>..] - ETA: 0s - loss: 0.1629 - accuracy: 0.9415\n",
      "Epoch 5: val_loss did not improve from 0.15173\n",
      "1250/1250 [==============================] - 1s 722us/step - loss: 0.1640 - accuracy: 0.9415 - val_loss: 0.2607 - val_accuracy: 0.9172 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1181/1250 [===========================>..] - ETA: 0s - loss: 0.1554 - accuracy: 0.9446\n",
      "Epoch 6: val_loss did not improve from 0.15173\n",
      "1250/1250 [==============================] - 1s 720us/step - loss: 0.1555 - accuracy: 0.9442 - val_loss: 0.1769 - val_accuracy: 0.9510 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1204/1250 [===========================>..] - ETA: 0s - loss: 0.1499 - accuracy: 0.9455\n",
      "Epoch 7: val_loss did not improve from 0.15173\n",
      "1250/1250 [==============================] - 1s 745us/step - loss: 0.1494 - accuracy: 0.9457 - val_loss: 0.1729 - val_accuracy: 0.9476 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1180/1250 [===========================>..] - ETA: 0s - loss: 0.1488 - accuracy: 0.9469\n",
      "Epoch 8: val_loss improved from 0.15173 to 0.12835, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 774us/step - loss: 0.1475 - accuracy: 0.9477 - val_loss: 0.1284 - val_accuracy: 0.9628 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1198/1250 [===========================>..] - ETA: 0s - loss: 0.1428 - accuracy: 0.9493\n",
      "Epoch 9: val_loss did not improve from 0.12835\n",
      "1250/1250 [==============================] - 1s 707us/step - loss: 0.1426 - accuracy: 0.9492 - val_loss: 0.1483 - val_accuracy: 0.9541 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1206/1250 [===========================>..] - ETA: 0s - loss: 0.1302 - accuracy: 0.9542\n",
      "Epoch 10: val_loss improved from 0.12835 to 0.12339, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 712us/step - loss: 0.1306 - accuracy: 0.9542 - val_loss: 0.1234 - val_accuracy: 0.9647 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "1201/1250 [===========================>..] - ETA: 0s - loss: 0.1283 - accuracy: 0.9566\n",
      "Epoch 11: val_loss did not improve from 0.12339\n",
      "1250/1250 [==============================] - 1s 707us/step - loss: 0.1277 - accuracy: 0.9567 - val_loss: 0.1627 - val_accuracy: 0.9555 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "1214/1250 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.9576\n",
      "Epoch 12: val_loss improved from 0.12339 to 0.12063, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 755us/step - loss: 0.1260 - accuracy: 0.9576 - val_loss: 0.1206 - val_accuracy: 0.9668 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "1215/1250 [============================>.] - ETA: 0s - loss: 0.1249 - accuracy: 0.9567\n",
      "Epoch 13: val_loss improved from 0.12063 to 0.12060, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 755us/step - loss: 0.1251 - accuracy: 0.9568 - val_loss: 0.1206 - val_accuracy: 0.9635 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "1193/1250 [===========================>..] - ETA: 0s - loss: 0.1268 - accuracy: 0.9562\n",
      "Epoch 14: val_loss improved from 0.12060 to 0.11990, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 720us/step - loss: 0.1262 - accuracy: 0.9565 - val_loss: 0.1199 - val_accuracy: 0.9651 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "1202/1250 [===========================>..] - ETA: 0s - loss: 0.1222 - accuracy: 0.9584\n",
      "Epoch 15: val_loss did not improve from 0.11990\n",
      "1250/1250 [==============================] - 1s 706us/step - loss: 0.1217 - accuracy: 0.9586 - val_loss: 0.1265 - val_accuracy: 0.9635 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.1245 - accuracy: 0.9579\n",
      "Epoch 16: val_loss improved from 0.11990 to 0.11206, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 780us/step - loss: 0.1246 - accuracy: 0.9579 - val_loss: 0.1121 - val_accuracy: 0.9679 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "1178/1250 [===========================>..] - ETA: 0s - loss: 0.1216 - accuracy: 0.9590\n",
      "Epoch 17: val_loss did not improve from 0.11206\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 0.1218 - accuracy: 0.9591 - val_loss: 0.1405 - val_accuracy: 0.9599 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "1210/1250 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.9590\n",
      "Epoch 18: val_loss did not improve from 0.11206\n",
      "1250/1250 [==============================] - 1s 743us/step - loss: 0.1212 - accuracy: 0.9588 - val_loss: 0.1294 - val_accuracy: 0.9614 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.1199 - accuracy: 0.9583\n",
      "Epoch 19: val_loss did not improve from 0.11206\n",
      "1250/1250 [==============================] - 1s 730us/step - loss: 0.1198 - accuracy: 0.9582 - val_loss: 0.1929 - val_accuracy: 0.9462 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "1203/1250 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.9618\n",
      "Epoch 20: val_loss did not improve from 0.11206\n",
      "1250/1250 [==============================] - 1s 751us/step - loss: 0.1149 - accuracy: 0.9620 - val_loss: 0.2549 - val_accuracy: 0.9118 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "1194/1250 [===========================>..] - ETA: 0s - loss: 0.1137 - accuracy: 0.9626\n",
      "Epoch 21: val_loss did not improve from 0.11206\n",
      "1250/1250 [==============================] - 1s 711us/step - loss: 0.1130 - accuracy: 0.9627 - val_loss: 0.1615 - val_accuracy: 0.9551 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "1202/1250 [===========================>..] - ETA: 0s - loss: 0.1127 - accuracy: 0.9621\n",
      "Epoch 22: val_loss did not improve from 0.11206\n",
      "1250/1250 [==============================] - 1s 797us/step - loss: 0.1130 - accuracy: 0.9621 - val_loss: 0.2500 - val_accuracy: 0.9147 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 0.9619\n",
      "Epoch 23: val_loss did not improve from 0.11206\n",
      "1250/1250 [==============================] - 1s 875us/step - loss: 0.1125 - accuracy: 0.9618 - val_loss: 0.2444 - val_accuracy: 0.9150 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "1183/1250 [===========================>..] - ETA: 0s - loss: 0.1127 - accuracy: 0.9617\n",
      "Epoch 24: val_loss did not improve from 0.11206\n",
      "1250/1250 [==============================] - 1s 766us/step - loss: 0.1117 - accuracy: 0.9621 - val_loss: 0.2191 - val_accuracy: 0.9307 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "1230/1250 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.9627\n",
      "Epoch 25: val_loss improved from 0.11206 to 0.10647, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 748us/step - loss: 0.1107 - accuracy: 0.9628 - val_loss: 0.1065 - val_accuracy: 0.9694 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "1177/1250 [===========================>..] - ETA: 0s - loss: 0.1084 - accuracy: 0.9627\n",
      "Epoch 26: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 762us/step - loss: 0.1083 - accuracy: 0.9629 - val_loss: 0.1115 - val_accuracy: 0.9695 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "1184/1250 [===========================>..] - ETA: 0s - loss: 0.1123 - accuracy: 0.9621\n",
      "Epoch 27: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 717us/step - loss: 0.1121 - accuracy: 0.9620 - val_loss: 0.1096 - val_accuracy: 0.9701 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "1183/1250 [===========================>..] - ETA: 0s - loss: 0.1099 - accuracy: 0.9630\n",
      "Epoch 28: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 716us/step - loss: 0.1100 - accuracy: 0.9632 - val_loss: 0.1078 - val_accuracy: 0.9687 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "1203/1250 [===========================>..] - ETA: 0s - loss: 0.1098 - accuracy: 0.9631\n",
      "Epoch 29: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 706us/step - loss: 0.1102 - accuracy: 0.9631 - val_loss: 0.1125 - val_accuracy: 0.9679 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "1210/1250 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9643\n",
      "Epoch 30: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 751us/step - loss: 0.1058 - accuracy: 0.9645 - val_loss: 0.1096 - val_accuracy: 0.9693 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "1196/1250 [===========================>..] - ETA: 0s - loss: 0.1074 - accuracy: 0.9649\n",
      "Epoch 31: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 709us/step - loss: 0.1077 - accuracy: 0.9651 - val_loss: 0.1101 - val_accuracy: 0.9685 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "1230/1250 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9644\n",
      "Epoch 32: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 780us/step - loss: 0.1055 - accuracy: 0.9644 - val_loss: 0.2936 - val_accuracy: 0.8814 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "1190/1250 [===========================>..] - ETA: 0s - loss: 0.1052 - accuracy: 0.9646\n",
      "Epoch 33: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 712us/step - loss: 0.1053 - accuracy: 0.9648 - val_loss: 0.2712 - val_accuracy: 0.8978 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "1217/1250 [============================>.] - ETA: 0s - loss: 0.1036 - accuracy: 0.9650\n",
      "Epoch 34: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 748us/step - loss: 0.1037 - accuracy: 0.9650 - val_loss: 0.1088 - val_accuracy: 0.9693 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "1181/1250 [===========================>..] - ETA: 0s - loss: 0.1043 - accuracy: 0.9648\n",
      "Epoch 35: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 757us/step - loss: 0.1038 - accuracy: 0.9652 - val_loss: 0.1324 - val_accuracy: 0.9644 - lr: 1.2500e-04\n",
      "Epoch 35: early stopping\n",
      "accuracy: 96.93999886512756%\n",
      "Epoch 1/100\n",
      "1177/1250 [===========================>..] - ETA: 0s - loss: 0.4501 - accuracy: 0.7860\n",
      "Epoch 1: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 811us/step - loss: 0.4397 - accuracy: 0.7919 - val_loss: 0.1948 - val_accuracy: 0.9508 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1181/1250 [===========================>..] - ETA: 0s - loss: 0.2249 - accuracy: 0.9139\n",
      "Epoch 2: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 717us/step - loss: 0.2217 - accuracy: 0.9154 - val_loss: 0.2027 - val_accuracy: 0.9356 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1205/1250 [===========================>..] - ETA: 0s - loss: 0.1844 - accuracy: 0.9331\n",
      "Epoch 3: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 718us/step - loss: 0.1840 - accuracy: 0.9334 - val_loss: 0.1442 - val_accuracy: 0.9608 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.1674 - accuracy: 0.9396\n",
      "Epoch 4: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 770us/step - loss: 0.1675 - accuracy: 0.9396 - val_loss: 0.1648 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1202/1250 [===========================>..] - ETA: 0s - loss: 0.1620 - accuracy: 0.9423\n",
      "Epoch 5: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 706us/step - loss: 0.1634 - accuracy: 0.9418 - val_loss: 0.1516 - val_accuracy: 0.9554 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1196/1250 [===========================>..] - ETA: 0s - loss: 0.1528 - accuracy: 0.9445\n",
      "Epoch 6: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 710us/step - loss: 0.1522 - accuracy: 0.9450 - val_loss: 0.1440 - val_accuracy: 0.9587 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1202/1250 [===========================>..] - ETA: 0s - loss: 0.1506 - accuracy: 0.9456\n",
      "Epoch 7: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 707us/step - loss: 0.1507 - accuracy: 0.9457 - val_loss: 0.1637 - val_accuracy: 0.9566 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1207/1250 [===========================>..] - ETA: 0s - loss: 0.1475 - accuracy: 0.9479\n",
      "Epoch 8: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 704us/step - loss: 0.1475 - accuracy: 0.9476 - val_loss: 0.1426 - val_accuracy: 0.9536 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1207/1250 [===========================>..] - ETA: 0s - loss: 0.1414 - accuracy: 0.9481\n",
      "Epoch 9: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 752us/step - loss: 0.1417 - accuracy: 0.9485 - val_loss: 0.1451 - val_accuracy: 0.9576 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1234/1250 [============================>.] - ETA: 0s - loss: 0.1294 - accuracy: 0.9552\n",
      "Epoch 10: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 771us/step - loss: 0.1295 - accuracy: 0.9553 - val_loss: 0.1890 - val_accuracy: 0.9438 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "1237/1250 [============================>.] - ETA: 0s - loss: 0.1259 - accuracy: 0.9565\n",
      "Epoch 11: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 730us/step - loss: 0.1258 - accuracy: 0.9564 - val_loss: 0.1329 - val_accuracy: 0.9602 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "1182/1250 [===========================>..] - ETA: 0s - loss: 0.1264 - accuracy: 0.9570\n",
      "Epoch 12: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 716us/step - loss: 0.1254 - accuracy: 0.9571 - val_loss: 0.1338 - val_accuracy: 0.9596 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "1198/1250 [===========================>..] - ETA: 0s - loss: 0.1197 - accuracy: 0.9602\n",
      "Epoch 13: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 708us/step - loss: 0.1203 - accuracy: 0.9598 - val_loss: 0.2225 - val_accuracy: 0.9312 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "1205/1250 [===========================>..] - ETA: 0s - loss: 0.1254 - accuracy: 0.9569\n",
      "Epoch 14: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 705us/step - loss: 0.1245 - accuracy: 0.9571 - val_loss: 0.1359 - val_accuracy: 0.9636 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "1182/1250 [===========================>..] - ETA: 0s - loss: 0.1235 - accuracy: 0.9567\n",
      "Epoch 15: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 716us/step - loss: 0.1255 - accuracy: 0.9561 - val_loss: 0.2384 - val_accuracy: 0.9255 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "1196/1250 [===========================>..] - ETA: 0s - loss: 0.1209 - accuracy: 0.9585\n",
      "Epoch 16: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 709us/step - loss: 0.1212 - accuracy: 0.9584 - val_loss: 0.2122 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "1196/1250 [===========================>..] - ETA: 0s - loss: 0.1229 - accuracy: 0.9575\n",
      "Epoch 17: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 708us/step - loss: 0.1219 - accuracy: 0.9578 - val_loss: 0.1266 - val_accuracy: 0.9633 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "1207/1250 [===========================>..] - ETA: 0s - loss: 0.1202 - accuracy: 0.9593\n",
      "Epoch 18: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 744us/step - loss: 0.1198 - accuracy: 0.9593 - val_loss: 0.1691 - val_accuracy: 0.9543 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "1171/1250 [===========================>..] - ETA: 0s - loss: 0.1198 - accuracy: 0.9592\n",
      "Epoch 19: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 788us/step - loss: 0.1183 - accuracy: 0.9594 - val_loss: 0.1285 - val_accuracy: 0.9612 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "1190/1250 [===========================>..] - ETA: 0s - loss: 0.1120 - accuracy: 0.9631\n",
      "Epoch 20: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 754us/step - loss: 0.1115 - accuracy: 0.9632 - val_loss: 0.1160 - val_accuracy: 0.9671 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "1217/1250 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9618\n",
      "Epoch 21: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 788us/step - loss: 0.1139 - accuracy: 0.9618 - val_loss: 0.1219 - val_accuracy: 0.9643 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "1190/1250 [===========================>..] - ETA: 0s - loss: 0.1126 - accuracy: 0.9623\n",
      "Epoch 22: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 755us/step - loss: 0.1117 - accuracy: 0.9630 - val_loss: 0.1179 - val_accuracy: 0.9663 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "1217/1250 [============================>.] - ETA: 0s - loss: 0.1105 - accuracy: 0.9639\n",
      "Epoch 23: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 704us/step - loss: 0.1110 - accuracy: 0.9637 - val_loss: 0.2595 - val_accuracy: 0.9181 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "1193/1250 [===========================>..] - ETA: 0s - loss: 0.1079 - accuracy: 0.9642\n",
      "Epoch 24: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 712us/step - loss: 0.1089 - accuracy: 0.9638 - val_loss: 0.1314 - val_accuracy: 0.9634 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "1203/1250 [===========================>..] - ETA: 0s - loss: 0.1111 - accuracy: 0.9637\n",
      "Epoch 25: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 706us/step - loss: 0.1110 - accuracy: 0.9638 - val_loss: 0.1332 - val_accuracy: 0.9606 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "1209/1250 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 0.9622\n",
      "Epoch 26: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 703us/step - loss: 0.1116 - accuracy: 0.9625 - val_loss: 0.2744 - val_accuracy: 0.9026 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "1201/1250 [===========================>..] - ETA: 0s - loss: 0.1102 - accuracy: 0.9647\n",
      "Epoch 27: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 714us/step - loss: 0.1099 - accuracy: 0.9649 - val_loss: 0.2722 - val_accuracy: 0.9144 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "1199/1250 [===========================>..] - ETA: 0s - loss: 0.1088 - accuracy: 0.9642\n",
      "Epoch 28: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 792us/step - loss: 0.1099 - accuracy: 0.9642 - val_loss: 0.2771 - val_accuracy: 0.9034 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "1194/1250 [===========================>..] - ETA: 0s - loss: 0.1089 - accuracy: 0.9634\n",
      "Epoch 29: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 716us/step - loss: 0.1090 - accuracy: 0.9633 - val_loss: 0.2688 - val_accuracy: 0.9035 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "1202/1250 [===========================>..] - ETA: 0s - loss: 0.1090 - accuracy: 0.9641\n",
      "Epoch 30: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 751us/step - loss: 0.1080 - accuracy: 0.9644 - val_loss: 0.1568 - val_accuracy: 0.9600 - lr: 1.2500e-04\n",
      "Epoch 30: early stopping\n",
      "accuracy: 96.96000218391418%\n",
      "Epoch 1/100\n",
      "1190/1250 [===========================>..] - ETA: 0s - loss: 0.4353 - accuracy: 0.7999\n",
      "Epoch 1: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 792us/step - loss: 0.4265 - accuracy: 0.8053 - val_loss: 0.2266 - val_accuracy: 0.9175 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1183/1250 [===========================>..] - ETA: 0s - loss: 0.2248 - accuracy: 0.9166\n",
      "Epoch 2: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 810us/step - loss: 0.2234 - accuracy: 0.9167 - val_loss: 0.1523 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1173/1250 [===========================>..] - ETA: 0s - loss: 0.1917 - accuracy: 0.9297\n",
      "Epoch 3: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 720us/step - loss: 0.1892 - accuracy: 0.9307 - val_loss: 0.1765 - val_accuracy: 0.9450 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1202/1250 [===========================>..] - ETA: 0s - loss: 0.1755 - accuracy: 0.9379\n",
      "Epoch 4: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 709us/step - loss: 0.1744 - accuracy: 0.9380 - val_loss: 0.1219 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1185/1250 [===========================>..] - ETA: 0s - loss: 0.1668 - accuracy: 0.9412\n",
      "Epoch 5: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 753us/step - loss: 0.1659 - accuracy: 0.9415 - val_loss: 0.1408 - val_accuracy: 0.9569 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1200/1250 [===========================>..] - ETA: 0s - loss: 0.1578 - accuracy: 0.9438\n",
      "Epoch 6: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 706us/step - loss: 0.1583 - accuracy: 0.9440 - val_loss: 0.1324 - val_accuracy: 0.9632 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1194/1250 [===========================>..] - ETA: 0s - loss: 0.1550 - accuracy: 0.9429\n",
      "Epoch 7: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 710us/step - loss: 0.1553 - accuracy: 0.9431 - val_loss: 0.1591 - val_accuracy: 0.9568 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1193/1250 [===========================>..] - ETA: 0s - loss: 0.1496 - accuracy: 0.9474\n",
      "Epoch 8: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 709us/step - loss: 0.1486 - accuracy: 0.9477 - val_loss: 0.1221 - val_accuracy: 0.9635 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1201/1250 [===========================>..] - ETA: 0s - loss: 0.1476 - accuracy: 0.9468\n",
      "Epoch 9: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 706us/step - loss: 0.1469 - accuracy: 0.9470 - val_loss: 0.1172 - val_accuracy: 0.9661 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1189/1250 [===========================>..] - ETA: 0s - loss: 0.1331 - accuracy: 0.9560\n",
      "Epoch 10: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 713us/step - loss: 0.1337 - accuracy: 0.9559 - val_loss: 0.1201 - val_accuracy: 0.9669 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "1194/1250 [===========================>..] - ETA: 0s - loss: 0.1326 - accuracy: 0.9555\n",
      "Epoch 11: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 711us/step - loss: 0.1327 - accuracy: 0.9555 - val_loss: 0.1391 - val_accuracy: 0.9638 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "1180/1250 [===========================>..] - ETA: 0s - loss: 0.1316 - accuracy: 0.9556\n",
      "Epoch 12: val_loss did not improve from 0.10647\n",
      "1250/1250 [==============================] - 1s 719us/step - loss: 0.1319 - accuracy: 0.9557 - val_loss: 0.1402 - val_accuracy: 0.9616 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "1203/1250 [===========================>..] - ETA: 0s - loss: 0.1290 - accuracy: 0.9562\n",
      "Epoch 13: val_loss improved from 0.10647 to 0.10458, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 814us/step - loss: 0.1288 - accuracy: 0.9562 - val_loss: 0.1046 - val_accuracy: 0.9701 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "1181/1250 [===========================>..] - ETA: 0s - loss: 0.1266 - accuracy: 0.9578\n",
      "Epoch 14: val_loss did not improve from 0.10458\n",
      "1250/1250 [==============================] - 1s 760us/step - loss: 0.1272 - accuracy: 0.9574 - val_loss: 0.1199 - val_accuracy: 0.9678 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.9569\n",
      "Epoch 15: val_loss improved from 0.10458 to 0.09958, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 734us/step - loss: 0.1269 - accuracy: 0.9570 - val_loss: 0.0996 - val_accuracy: 0.9716 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "1214/1250 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.9592\n",
      "Epoch 16: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 785us/step - loss: 0.1228 - accuracy: 0.9590 - val_loss: 0.1895 - val_accuracy: 0.9508 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "1187/1250 [===========================>..] - ETA: 0s - loss: 0.1282 - accuracy: 0.9563\n",
      "Epoch 17: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 712us/step - loss: 0.1288 - accuracy: 0.9562 - val_loss: 0.1310 - val_accuracy: 0.9663 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "1210/1250 [============================>.] - ETA: 0s - loss: 0.1265 - accuracy: 0.9567\n",
      "Epoch 18: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 704us/step - loss: 0.1257 - accuracy: 0.9571 - val_loss: 0.1146 - val_accuracy: 0.9702 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "1206/1250 [===========================>..] - ETA: 0s - loss: 0.1271 - accuracy: 0.9564\n",
      "Epoch 19: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 704us/step - loss: 0.1268 - accuracy: 0.9566 - val_loss: 0.1825 - val_accuracy: 0.9472 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "1208/1250 [===========================>..] - ETA: 0s - loss: 0.1167 - accuracy: 0.9619\n",
      "Epoch 20: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 703us/step - loss: 0.1168 - accuracy: 0.9617 - val_loss: 0.1135 - val_accuracy: 0.9701 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "1186/1250 [===========================>..] - ETA: 0s - loss: 0.1140 - accuracy: 0.9612\n",
      "Epoch 21: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 713us/step - loss: 0.1158 - accuracy: 0.9609 - val_loss: 0.1510 - val_accuracy: 0.9616 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "1193/1250 [===========================>..] - ETA: 0s - loss: 0.1155 - accuracy: 0.9615\n",
      "Epoch 22: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 810us/step - loss: 0.1149 - accuracy: 0.9616 - val_loss: 0.1201 - val_accuracy: 0.9700 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "1212/1250 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 0.9627\n",
      "Epoch 23: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 703us/step - loss: 0.1160 - accuracy: 0.9625 - val_loss: 0.1938 - val_accuracy: 0.9477 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "1183/1250 [===========================>..] - ETA: 0s - loss: 0.1138 - accuracy: 0.9622\n",
      "Epoch 24: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 772us/step - loss: 0.1147 - accuracy: 0.9620 - val_loss: 0.1147 - val_accuracy: 0.9696 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "1218/1250 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9623\n",
      "Epoch 25: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 0.1142 - accuracy: 0.9622 - val_loss: 0.1198 - val_accuracy: 0.9700 - lr: 2.5000e-04\n",
      "Epoch 25: early stopping\n",
      "accuracy: 97.15999960899353%\n",
      "Epoch 1/100\n",
      "1206/1250 [===========================>..] - ETA: 0s - loss: 0.4494 - accuracy: 0.7940\n",
      "Epoch 1: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 772us/step - loss: 0.4421 - accuracy: 0.7980 - val_loss: 0.2154 - val_accuracy: 0.9381 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1173/1250 [===========================>..] - ETA: 0s - loss: 0.2247 - accuracy: 0.9181\n",
      "Epoch 2: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 719us/step - loss: 0.2223 - accuracy: 0.9190 - val_loss: 0.1518 - val_accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1224/1250 [============================>.] - ETA: 0s - loss: 0.1831 - accuracy: 0.9334\n",
      "Epoch 3: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 694us/step - loss: 0.1824 - accuracy: 0.9335 - val_loss: 0.1412 - val_accuracy: 0.9599 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1230/1250 [============================>.] - ETA: 0s - loss: 0.1676 - accuracy: 0.9410\n",
      "Epoch 4: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 689us/step - loss: 0.1675 - accuracy: 0.9410 - val_loss: 0.1538 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1229/1250 [============================>.] - ETA: 0s - loss: 0.1566 - accuracy: 0.9452\n",
      "Epoch 5: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 691us/step - loss: 0.1563 - accuracy: 0.9453 - val_loss: 0.1364 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1231/1250 [============================>.] - ETA: 0s - loss: 0.1513 - accuracy: 0.9479\n",
      "Epoch 6: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 691us/step - loss: 0.1514 - accuracy: 0.9478 - val_loss: 0.1387 - val_accuracy: 0.9618 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1226/1250 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.9471\n",
      "Epoch 7: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 693us/step - loss: 0.1495 - accuracy: 0.9470 - val_loss: 0.1473 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1227/1250 [============================>.] - ETA: 0s - loss: 0.1440 - accuracy: 0.9500\n",
      "Epoch 8: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 690us/step - loss: 0.1442 - accuracy: 0.9499 - val_loss: 0.1895 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1226/1250 [============================>.] - ETA: 0s - loss: 0.1409 - accuracy: 0.9501\n",
      "Epoch 9: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 736us/step - loss: 0.1412 - accuracy: 0.9500 - val_loss: 0.1605 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1213/1250 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9551\n",
      "Epoch 10: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 755us/step - loss: 0.1295 - accuracy: 0.9551 - val_loss: 0.1858 - val_accuracy: 0.9470 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "1184/1250 [===========================>..] - ETA: 0s - loss: 0.1302 - accuracy: 0.9565\n",
      "Epoch 11: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 799us/step - loss: 0.1303 - accuracy: 0.9565 - val_loss: 0.1401 - val_accuracy: 0.9593 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "1188/1250 [===========================>..] - ETA: 0s - loss: 0.1265 - accuracy: 0.9580\n",
      "Epoch 12: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 711us/step - loss: 0.1263 - accuracy: 0.9581 - val_loss: 0.1196 - val_accuracy: 0.9646 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "1214/1250 [============================>.] - ETA: 0s - loss: 0.1269 - accuracy: 0.9574\n",
      "Epoch 13: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 699us/step - loss: 0.1268 - accuracy: 0.9574 - val_loss: 0.1281 - val_accuracy: 0.9631 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "1198/1250 [===========================>..] - ETA: 0s - loss: 0.1244 - accuracy: 0.9567\n",
      "Epoch 14: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 748us/step - loss: 0.1238 - accuracy: 0.9568 - val_loss: 0.2187 - val_accuracy: 0.9306 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "1231/1250 [============================>.] - ETA: 0s - loss: 0.1212 - accuracy: 0.9587\n",
      "Epoch 15: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 690us/step - loss: 0.1212 - accuracy: 0.9589 - val_loss: 0.1149 - val_accuracy: 0.9647 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "1217/1250 [============================>.] - ETA: 0s - loss: 0.1202 - accuracy: 0.9603\n",
      "Epoch 16: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 697us/step - loss: 0.1204 - accuracy: 0.9604 - val_loss: 0.1133 - val_accuracy: 0.9672 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "1222/1250 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.9593\n",
      "Epoch 17: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 695us/step - loss: 0.1213 - accuracy: 0.9593 - val_loss: 0.1180 - val_accuracy: 0.9642 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "1216/1250 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9599\n",
      "Epoch 18: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 702us/step - loss: 0.1211 - accuracy: 0.9597 - val_loss: 0.2528 - val_accuracy: 0.9151 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "1208/1250 [===========================>..] - ETA: 0s - loss: 0.1174 - accuracy: 0.9598\n",
      "Epoch 19: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 702us/step - loss: 0.1168 - accuracy: 0.9599 - val_loss: 0.1068 - val_accuracy: 0.9681 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "1231/1250 [============================>.] - ETA: 0s - loss: 0.1162 - accuracy: 0.9626\n",
      "Epoch 20: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 690us/step - loss: 0.1166 - accuracy: 0.9625 - val_loss: 0.2294 - val_accuracy: 0.9251 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "1218/1250 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.9621\n",
      "Epoch 21: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 698us/step - loss: 0.1125 - accuracy: 0.9621 - val_loss: 0.1102 - val_accuracy: 0.9672 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "1187/1250 [===========================>..] - ETA: 0s - loss: 0.1124 - accuracy: 0.9636\n",
      "Epoch 22: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 810us/step - loss: 0.1128 - accuracy: 0.9634 - val_loss: 0.2097 - val_accuracy: 0.9335 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9641\n",
      "Epoch 23: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 763us/step - loss: 0.1093 - accuracy: 0.9641 - val_loss: 0.1243 - val_accuracy: 0.9647 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "1217/1250 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.9625\n",
      "Epoch 24: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 697us/step - loss: 0.1128 - accuracy: 0.9624 - val_loss: 0.2444 - val_accuracy: 0.9198 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "1227/1250 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9644\n",
      "Epoch 25: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 693us/step - loss: 0.1059 - accuracy: 0.9644 - val_loss: 0.2075 - val_accuracy: 0.9373 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "1221/1250 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9642\n",
      "Epoch 26: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 696us/step - loss: 0.1112 - accuracy: 0.9642 - val_loss: 0.1071 - val_accuracy: 0.9688 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.9640\n",
      "Epoch 27: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 725us/step - loss: 0.1117 - accuracy: 0.9639 - val_loss: 0.1165 - val_accuracy: 0.9647 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "1229/1250 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 0.9627\n",
      "Epoch 28: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 691us/step - loss: 0.1125 - accuracy: 0.9628 - val_loss: 0.1102 - val_accuracy: 0.9671 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "1230/1250 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9642\n",
      "Epoch 29: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 691us/step - loss: 0.1100 - accuracy: 0.9642 - val_loss: 0.1556 - val_accuracy: 0.9569 - lr: 2.5000e-04\n",
      "Epoch 29: early stopping\n",
      "accuracy: 96.81000113487244%\n",
      "Epoch 1/100\n",
      "1223/1250 [============================>.] - ETA: 0s - loss: 0.4254 - accuracy: 0.8083\n",
      "Epoch 1: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 741us/step - loss: 0.4224 - accuracy: 0.8099 - val_loss: 0.1933 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1205/1250 [===========================>..] - ETA: 0s - loss: 0.2182 - accuracy: 0.9186\n",
      "Epoch 2: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 714us/step - loss: 0.2177 - accuracy: 0.9190 - val_loss: 0.1953 - val_accuracy: 0.9469 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1216/1250 [============================>.] - ETA: 0s - loss: 0.1845 - accuracy: 0.9328\n",
      "Epoch 3: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 741us/step - loss: 0.1848 - accuracy: 0.9327 - val_loss: 0.2051 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.1702 - accuracy: 0.9383\n",
      "Epoch 4: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 816us/step - loss: 0.1703 - accuracy: 0.9384 - val_loss: 0.1869 - val_accuracy: 0.9590 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1188/1250 [===========================>..] - ETA: 0s - loss: 0.1578 - accuracy: 0.9430\n",
      "Epoch 5: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 753us/step - loss: 0.1588 - accuracy: 0.9427 - val_loss: 0.2512 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1227/1250 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9434\n",
      "Epoch 6: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 693us/step - loss: 0.1551 - accuracy: 0.9434 - val_loss: 0.2057 - val_accuracy: 0.9590 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1223/1250 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9455\n",
      "Epoch 7: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 697us/step - loss: 0.1515 - accuracy: 0.9452 - val_loss: 0.2666 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1232/1250 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9464\n",
      "Epoch 8: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 731us/step - loss: 0.1501 - accuracy: 0.9460 - val_loss: 0.1891 - val_accuracy: 0.9617 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1237/1250 [============================>.] - ETA: 0s - loss: 0.1476 - accuracy: 0.9468\n",
      "Epoch 9: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 729us/step - loss: 0.1474 - accuracy: 0.9469 - val_loss: 0.1400 - val_accuracy: 0.9585 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1222/1250 [============================>.] - ETA: 0s - loss: 0.1319 - accuracy: 0.9549\n",
      "Epoch 10: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 695us/step - loss: 0.1317 - accuracy: 0.9548 - val_loss: 0.1225 - val_accuracy: 0.9613 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "1229/1250 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 0.9536\n",
      "Epoch 11: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 692us/step - loss: 0.1308 - accuracy: 0.9537 - val_loss: 0.1188 - val_accuracy: 0.9639 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "1226/1250 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9559\n",
      "Epoch 12: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 692us/step - loss: 0.1303 - accuracy: 0.9561 - val_loss: 0.1582 - val_accuracy: 0.9646 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "1217/1250 [============================>.] - ETA: 0s - loss: 0.1240 - accuracy: 0.9572\n",
      "Epoch 13: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 698us/step - loss: 0.1249 - accuracy: 0.9570 - val_loss: 0.1147 - val_accuracy: 0.9683 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "1229/1250 [============================>.] - ETA: 0s - loss: 0.1246 - accuracy: 0.9571\n",
      "Epoch 14: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 692us/step - loss: 0.1245 - accuracy: 0.9571 - val_loss: 0.1042 - val_accuracy: 0.9678 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "1210/1250 [============================>.] - ETA: 0s - loss: 0.1302 - accuracy: 0.9552\n",
      "Epoch 15: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 758us/step - loss: 0.1297 - accuracy: 0.9556 - val_loss: 0.1102 - val_accuracy: 0.9674 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "1175/1250 [===========================>..] - ETA: 0s - loss: 0.1232 - accuracy: 0.9586\n",
      "Epoch 16: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 804us/step - loss: 0.1227 - accuracy: 0.9588 - val_loss: 0.1045 - val_accuracy: 0.9684 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "1199/1250 [===========================>..] - ETA: 0s - loss: 0.1227 - accuracy: 0.9598\n",
      "Epoch 17: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 705us/step - loss: 0.1235 - accuracy: 0.9596 - val_loss: 0.1094 - val_accuracy: 0.9668 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "1222/1250 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9591\n",
      "Epoch 18: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 693us/step - loss: 0.1228 - accuracy: 0.9591 - val_loss: 0.1096 - val_accuracy: 0.9661 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "1220/1250 [============================>.] - ETA: 0s - loss: 0.1250 - accuracy: 0.9588\n",
      "Epoch 19: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 695us/step - loss: 0.1250 - accuracy: 0.9588 - val_loss: 0.1189 - val_accuracy: 0.9625 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "1215/1250 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.9610\n",
      "Epoch 20: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 748us/step - loss: 0.1175 - accuracy: 0.9610 - val_loss: 0.1042 - val_accuracy: 0.9683 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "1214/1250 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.9623\n",
      "Epoch 21: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 699us/step - loss: 0.1147 - accuracy: 0.9625 - val_loss: 0.1049 - val_accuracy: 0.9671 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "1223/1250 [============================>.] - ETA: 0s - loss: 0.1154 - accuracy: 0.9626\n",
      "Epoch 22: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 695us/step - loss: 0.1147 - accuracy: 0.9628 - val_loss: 0.1001 - val_accuracy: 0.9689 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "1219/1250 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.9633\n",
      "Epoch 23: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 695us/step - loss: 0.1123 - accuracy: 0.9633 - val_loss: 0.1002 - val_accuracy: 0.9701 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "1218/1250 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.9635\n",
      "Epoch 24: val_loss did not improve from 0.09958\n",
      "1250/1250 [==============================] - 1s 696us/step - loss: 0.1124 - accuracy: 0.9635 - val_loss: 0.1043 - val_accuracy: 0.9674 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "1215/1250 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.9628\n",
      "Epoch 25: val_loss improved from 0.09958 to 0.09659, saving model to best_model.keras\n",
      "1250/1250 [==============================] - 1s 712us/step - loss: 0.1119 - accuracy: 0.9629 - val_loss: 0.0966 - val_accuracy: 0.9698 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "1227/1250 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.9639\n",
      "Epoch 26: val_loss did not improve from 0.09659\n",
      "1250/1250 [==============================] - 1s 738us/step - loss: 0.1112 - accuracy: 0.9638 - val_loss: 0.1055 - val_accuracy: 0.9673 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.9641\n",
      "Epoch 27: val_loss did not improve from 0.09659\n",
      "1250/1250 [==============================] - 1s 820us/step - loss: 0.1097 - accuracy: 0.9640 - val_loss: 0.1041 - val_accuracy: 0.9699 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "1177/1250 [===========================>..] - ETA: 0s - loss: 0.1111 - accuracy: 0.9635\n",
      "Epoch 28: val_loss did not improve from 0.09659\n",
      "1250/1250 [==============================] - 1s 800us/step - loss: 0.1112 - accuracy: 0.9633 - val_loss: 0.0999 - val_accuracy: 0.9689 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "1220/1250 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9640\n",
      "Epoch 29: val_loss did not improve from 0.09659\n",
      "1250/1250 [==============================] - 1s 695us/step - loss: 0.1112 - accuracy: 0.9639 - val_loss: 0.1062 - val_accuracy: 0.9667 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "1211/1250 [============================>.] - ETA: 0s - loss: 0.1072 - accuracy: 0.9655\n",
      "Epoch 30: val_loss did not improve from 0.09659\n",
      "1250/1250 [==============================] - 1s 704us/step - loss: 0.1072 - accuracy: 0.9654 - val_loss: 0.1002 - val_accuracy: 0.9690 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "1206/1250 [===========================>..] - ETA: 0s - loss: 0.1074 - accuracy: 0.9660\n",
      "Epoch 31: val_loss did not improve from 0.09659\n",
      "1250/1250 [==============================] - 1s 703us/step - loss: 0.1076 - accuracy: 0.9658 - val_loss: 0.0982 - val_accuracy: 0.9702 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "1197/1250 [===========================>..] - ETA: 0s - loss: 0.1055 - accuracy: 0.9655\n",
      "Epoch 32: val_loss did not improve from 0.09659\n",
      "1250/1250 [==============================] - 1s 707us/step - loss: 0.1061 - accuracy: 0.9653 - val_loss: 0.0987 - val_accuracy: 0.9702 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "1226/1250 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 0.9657\n",
      "Epoch 33: val_loss did not improve from 0.09659\n",
      "1250/1250 [==============================] - 1s 693us/step - loss: 0.1055 - accuracy: 0.9657 - val_loss: 0.0988 - val_accuracy: 0.9707 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "1210/1250 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9661\n",
      "Epoch 34: val_loss did not improve from 0.09659\n",
      "1250/1250 [==============================] - 1s 702us/step - loss: 0.1067 - accuracy: 0.9660 - val_loss: 0.0997 - val_accuracy: 0.9707 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.1071 - accuracy: 0.9652\n",
      "Epoch 35: val_loss did not improve from 0.09659\n",
      "1250/1250 [==============================] - 1s 726us/step - loss: 0.1071 - accuracy: 0.9653 - val_loss: 0.1020 - val_accuracy: 0.9689 - lr: 1.2500e-04\n",
      "Epoch 35: early stopping\n",
      "accuracy: 96.97999954223633%\n",
      "Average Accuracy: 96.97000026702881% (+/- 0.11207096280884013)%\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "import math\n",
    "\n",
    "# References : Multi-Class Classification Tutorial with the Keras Deep Learning Library - Machine Learning Mastery,neural-network-multiclass-classification-model-using-tensorflow,Multiclass Classification with Keras | HackerNoon,\n",
    "\n",
    "train_data = pd.read_csv('/Users/arina/Downloads/celestial_train.csv') # pls change this with the path from your local @ datathon team\n",
    "\n",
    "# Prepare training data\n",
    "train_data = train_data.drop(columns=['id'])\n",
    "X = train_data.drop('class', axis=1)\n",
    "y = train_data['class']\n",
    "label_encoder = LabelEncoder()# Encode the target variable\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_encoded = to_categorical(y_encoded)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Compute class weights for handling class imbalance calculated using the library \n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# the neural network \n",
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(128, input_shape=input_shape, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to define a learning rate schedule using common standards\n",
    "def step_decay(epoch): \n",
    "    initial_lr = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lr = initial_lr * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lr\n",
    "\n",
    "# Learning rate schedule callback to prevent overfitting \n",
    "lr_schedule = LearningRateScheduler(step_decay)\n",
    "\n",
    "# Early stopping and model checkpointing to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# K-Fold Cross-Validation to improve the model \n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cvscores = []\n",
    "\n",
    "for train, val in kfold.split(X_scaled, y_encoded.argmax(axis=1)):\n",
    "    # Split data\n",
    "    X_train, X_val = X_scaled[train], X_scaled[val]\n",
    "    y_train, y_val = y_encoded[train], y_encoded[val]\n",
    "\n",
    "    # Create model\n",
    "    model = create_model((X_train.shape[1],), y_encoded.shape[1])\n",
    "\n",
    "    # Train the model with learning rate scheduler, early stopping, and model checkpointing\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), \n",
    "              class_weight=class_weights_dict, verbose=1, callbacks=[lr_schedule, early_stopping, model_checkpoint])\n",
    "\n",
    "    # Load the best model \n",
    "    model.load_weights('best_model.keras')\n",
    "\n",
    "    # Evaluate the model\n",
    "    scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"{model.metrics_names[1]}: {scores[1] * 100}%\")\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "# Calculate and print average performance\n",
    "print(f\"Average Accuracy: {np.mean(cvscores)}% (+/- {np.std(cvscores)})%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "184f354d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 0s 248us/step\n",
      "Submission file saved to /Users/arina/Desktop/celestial_submission-2.csv\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('/Users/arina/Downloads/celestial_test.csv') # load the location of test file \n",
    "test_ids = test_data['id']  \n",
    "test_data = test_data.drop(columns=['id'])\n",
    "# use the model for prediction \n",
    "X_test_scaled = scaler.transform(test_data)\n",
    "y_pred_probabilities = model.predict(X_test_scaled)\n",
    "y_pred_classes = y_pred_probabilities.argmax(axis=1)\n",
    "\n",
    "# Get the labels back \n",
    "predicted_class_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'output': predicted_class_labels\n",
    "})\n",
    "\n",
    "#  path for saving the submission file\n",
    "submission_file_path = '/Users/arina/Desktop/celestial_submission-2.csv'\n",
    "\n",
    "# Save a new CSV file\n",
    "submission.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"Submission file saved to {submission_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccde3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
